{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af53f254-e319-4558-a1a7-f72115d72898",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef351086-ad20-414f-93ea-1366f63ca2fb",
   "metadata": {},
   "source": [
    "# Creación de datos sintéticos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ce2f65-a036-40e2-af3b-2659ece7952b",
   "metadata": {},
   "source": [
    "El conjunto de datos creado contiene textos generados por GPT2 para cada una de las 6 categorías, lo que significa que cada ejemplo tiene una etiqueta asociada. Este es un conjunto de datos etiquetado que es esencial para entrenar un modelo de clasificación supervisada.\n",
    "\n",
    "Este enfoque es útil cuando no se tiene acceso a un gran conjunto de datos etiquetados. GPT-2 genera ejemplos de texto que simulan lo que un humano podría escribir para cada categoría, lo que proporciona un volumen significativo de datos sintéticos que pueden ser utilizados para entrenar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35e80098-9058-443e-b4a8-6110d0363691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Verificar si hay una GPU disponible\n",
    "device_str = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # \"cuda\" para GPU, \"cpu\" para CPU\n",
    "print(device_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b5c84e8-b2ea-4499-9f59-bdf2c7d32ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo y el tokenizador de GPT-2\n",
    "model_name = \"gpt2\"  \n",
    "model = GPT2LMHeadModel.from_pretrained(model_name).to(device_str)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309f8bf5-1333-453d-a9e2-0a96bfa696a0",
   "metadata": {},
   "source": [
    "En el proceso de generación de datos sintéticos utilizando GPT-2 para entrenar un modelo de clasificación de texto, se probaron diferentes prompts (frases iniciales) para generar texto de manera que pudiera ser etiquetado correctamente en las seis categorías definidas: urgente, inteligencia artificial, computadoras, viajes, animales y ficción. Después de experimentar con varios prompts, se seleccionaron aquellos que generaban las salidas más coherentes y relevantes, asegurando que el texto generado correspondiera apropiadamente a cada categoría."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4126969a-b0dc-4e83-87b6-efeff9a03448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las categorías y la cantidad de sentencias por categoría\n",
    "candidate_labels = [\"urgent\", \"artificial_intelligence\", \"computer\", \"travel\", \"animal\", \"fiction\"]\n",
    "candidate_prompts = {\n",
    "    'urgent': 'Write a sentence that seems like an urgent request.',\n",
    "    'artificial_intelligence': 'Write a sentence that can be labeled as class artificial intelligence.',\n",
    "    'computer': 'Write a sentence that can be labeled as class computers.',\n",
    "    'travel': 'Write a sentence that can be labeled as class travels.',\n",
    "    'animal': 'Write a sentence that can be labeled as class animals.',\n",
    "    'fiction': 'Write a sentence that can be labeled as class fiction.'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0007b727-5aff-40cc-910f-c65e73d2bb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_sentences = 4000  \n",
    "\n",
    "# Función para generar texto usando GPT-2 con parámetros de variabilidad\n",
    "def generate_text(prompt, max_length=50, temperature=0.9, top_p=0.95, top_k=60):\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True, max_length=max_length).to(device_str)\n",
    "\n",
    "    # Generar texto utilizando el modelo\n",
    "    outputs = model.generate(\n",
    "        input_ids=inputs['input_ids'],  # Extraer input_ids del texto tokenizado\n",
    "        attention_mask=inputs['attention_mask'],  # Extraer attention_mask\n",
    "        max_length=max_length,\n",
    "        no_repeat_ngram_size=2,  # Evitar n-gramas repetidos\n",
    "        top_p=top_p,  # Muestreo por núcleo\n",
    "        top_k=top_k,  # Muestreo por top-k\n",
    "        temperature=temperature,  # Ajustar temperatura para variabilidad\n",
    "        pad_token_id=tokenizer.eos_token_id,  # ID del token de padding\n",
    "        do_sample=True  # Habilitar muestreo (para aleatoriedad)\n",
    "    )\n",
    "\n",
    "    # Decodificar el texto generado y devolver el resultado, omitiendo tokens especiales\n",
    "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    return generated_text[len(prompt):].strip()  # Devolver el texto excluyendo el prompt original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcda1647-8e9d-4f05-8234-7af49696f2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar ejemplos para cada categoría\n",
    "def create_data(label):\n",
    "    # Crear una lista para almacenar los resultados\n",
    "    labeled_data = []\n",
    "\n",
    "    # Generar ejemplos para cada categoría\n",
    "    print(f\"Generating examples for category: {label}\")\n",
    "    for _ in tqdm(range(num_sentences), desc=f\"Generating {label}\", ncols=100):\n",
    "        prompt = candidate_prompts[label]\n",
    "        \n",
    "        # un while en caso de que genere resultados menores a 30 palabras\n",
    "        len_flag = True\n",
    "        while len_flag:\n",
    "            generated_text = generate_text(prompt)\n",
    "            if len(generated_text.split()) > 30:\n",
    "              len_flag = False\n",
    "        # Agregar el texto y la categoría al resultado\n",
    "        result_dict = {\"text\": generated_text, \"label\": label}\n",
    "        labeled_data.append(result_dict)\n",
    "\n",
    "    return labeled_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5e1d9be-42d8-4cd2-bf35-e801380c0a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating examples for category: urgent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating urgent: 100%|██████████████████████████████████████████████| 1/1 [00:00<00:00,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating examples for category: artificial_intelligence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating artificial_intelligence: 100%|█████████████████████████████| 1/1 [00:00<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating examples for category: computer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating computer: 100%|████████████████████████████████████████████| 1/1 [00:00<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating examples for category: travel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating travel: 100%|██████████████████████████████████████████████| 1/1 [00:00<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating examples for category: animal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating animal: 100%|██████████████████████████████████████████████| 1/1 [00:00<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating examples for category: fiction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating fiction: 100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos guardados en: test.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# cantidad de iteraciones\n",
    "iterations = 1\n",
    "\n",
    "# Crear una lista vacía para almacenar los DataFrames\n",
    "all_data = []\n",
    "\n",
    "# Iterar a través de las iteraciones y etiquetas\n",
    "for i in range(iterations):\n",
    "    for label in candidate_labels:\n",
    "        # Crear los datos etiquetados\n",
    "        labeled_data = create_data(label)\n",
    "        df_labeled = pd.DataFrame(labeled_data)\n",
    "        all_data.append(df_labeled)\n",
    "\n",
    "# Concatenar todos los DataFrames en uno solo\n",
    "df_all = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "# Guardar el DataFrame combinado como un solo archivo Parquet\n",
    "output_path = f'gpt2_database_4k.parquet'\n",
    "df_all.to_parquet(output_path, index=False)\n",
    "\n",
    "print(f\"Datos guardados en: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47de7819-90a3-4530-a1de-3705a65181d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
